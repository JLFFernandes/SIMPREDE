{"timestamp":"2025-06-05T14:42:26.004077","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-06-05T14:42:26.004507","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/google_scraper_dag.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-06-05T14:42:26.026767Z","level":"info","event":"ğŸš€ Starting Airflow-Optimized Google News Scraper","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:26.029395Z","level":"info","event":"ğŸ“… Scraper Parameters:","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:26.029473Z","level":"info","event":"  - Days back: 1","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:26.029530Z","level":"info","event":"  - Specific date: None (use days_back)","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:26.029576Z","level":"info","event":"  - Max execution time: 3600 seconds (60.0 minutes)","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:26.029622Z","level":"info","event":"ğŸš€ Running Airflow scraper command: /home/airflow/.local/bin/python /opt/airflow/scripts/google_scraper/scraping/run_scraper_airflow.py --dias 1 --max_time 3600 --debug","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:26.029669Z","level":"info","event":"â° Process timeout will be: 3900 seconds (65.0 minutes)","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:26.029718Z","level":"info","event":"â° Waiting for process completion with timeout: 3900 seconds","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:26.327870Z","level":"info","event":"ğŸ“‹ A iniciar scraper do Google News (versÃ£o Airflow)","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:26.328137Z","level":"info","event":"ğŸ“‹ ParÃ¢metros: dias=1, date=None, max_time=3600, quiet=False","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:26.328204Z","level":"info","event":"ğŸ“‹ ğŸ“ Ficheiro de saÃ­da: /opt/airflow/data/raw/2025/06/04/intermediate_google_news_20250604.csv","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:26.328267Z","level":"info","event":"ğŸ“‹ â±ï¸ Tempo mÃ¡ximo de execuÃ§Ã£o: 3600 segundos","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:26.329618Z","level":"info","event":"ğŸ“‹ ğŸš€ A iniciar funÃ§Ã£o do scraper otimizada para Airflow","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:26.330392Z","level":"info","event":"ğŸ“‹ âš™ï¸  ParÃ¢metros: days_back=1, search_date=None, max_time=3600s","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:26.330469Z","level":"info","event":"ğŸ“‹ ğŸš€ A iniciar o scraper do Google News...","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:26.330522Z","level":"info","event":"ğŸ“‹ ğŸ“… Data: atual, Dias anteriores: 1","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:26.441821Z","level":"info","event":"ğŸ“‹ ğŸ“ Diretoria do script: /opt/airflow/scripts/google_scraper/scraping","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:26.441975Z","level":"info","event":"ğŸ“‹ ğŸ“ Raiz do projeto: /opt/airflow","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:26.442037Z","level":"info","event":"ğŸ“‹ ğŸ”§ A carregar ficheiros de configuraÃ§Ã£o...","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:27.284167Z","level":"info","event":"ğŸ“‹ ğŸ” A procurar ficheiros de configuraÃ§Ã£o em: ['/opt/airflow/config', '/opt/airflow/scripts/google_scraper/scraping/config', 'config']","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:27.285441Z","level":"info","event":"ğŸ“‹ 2025-06-05 15:42:27,284 - run_scraper_airflow - ERROR - âŒ NÃ£o foi possÃ­vel carregar o ficheiro keywords.json","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:27.289443Z","level":"info","event":"ğŸ“‹ 2025-06-05 15:42:27,284 - run_scraper_airflow - ERROR - ğŸ” Procurado em: ['/opt/airflow/config', '/opt/airflow/scripts/google_scraper/scraping/config', 'config']","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:27.290477Z","level":"info","event":"ğŸ“‹ 2025-06-05 15:42:27,284 - run_scraper_airflow - ERROR - âŒ Erro ao carregar configuraÃ§Ã£o: keywords.json nÃ£o encontrado","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:27.290553Z","level":"info","event":"ğŸ“‹ 2025-06-05 15:42:27,284 - run_scraper_airflow - ERROR - âŒ Scraper falhou: keywords.json nÃ£o encontrado","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:27.392504Z","level":"info","event":"âŒ Airflow scraper failed with return code 1","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:27.392711Z","level":"info","event":"âŒ Unexpected error in scraper task: Airflow scraper failed with return code 1","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:27.392826Z","level":"info","event":"ğŸ”„ Fallback: using original run_scraper.py...","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:27.392924Z","level":"info","event":"ğŸš€ Running fallback scraper command: python /opt/airflow/scripts/google_scraper/scraping/run_scraper.py --dias 1","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:27.393027Z","level":"info","event":"â° Fallback timeout: 3600 seconds (60.0 minutes)","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:27.423679Z","level":"info","event":"ğŸ“‹ Fallback scraper stdout:","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:27.423802Z","level":"info","event":"âš ï¸ Fallback scraper stderr: python: can't open file '/opt/airflow/scripts/google_scraper/scraping/run_scraper.py': [Errno 2] No such file or directory","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:27.423904Z","level":"info","event":"","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:42:27.423770","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"Exception","exc_value":"All scraper methods failed. Last error: python: can't open file '/opt/airflow/scripts/google_scraper/scraping/run_scraper.py': [Errno 2] No such file or directory\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.11/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":838,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.11/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1130,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.11/site-packages/airflow/sdk/bases/operator.py","lineno":408,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/standard/operators/python.py","lineno":212,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/standard/operators/python.py","lineno":235,"name":"execute_callable"},{"filename":"/home/airflow/.local/lib/python3.11/site-packages/airflow/sdk/execution_time/callback_runner.py","lineno":81,"name":"run"},{"filename":"/opt/airflow/dags/google_scraper_dag.py","lineno":174,"name":"run_scraper_task"}]},{"exc_type":"Exception","exc_value":"Airflow scraper failed with return code 1","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/opt/airflow/dags/google_scraper_dag.py","lineno":129,"name":"run_scraper_task"}]}]}
