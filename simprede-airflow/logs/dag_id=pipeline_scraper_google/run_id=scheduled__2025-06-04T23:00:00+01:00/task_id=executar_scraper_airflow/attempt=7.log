{"timestamp":"2025-06-05T14:41:13.199410","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-06-05T14:41:13.199852","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/google_scraper_dag.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-06-05T14:41:13.225589Z","level":"info","event":"ğŸš€ Starting Airflow-Optimized Google News Scraper","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:13.228011Z","level":"info","event":"ğŸ“… Scraper Parameters:","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:13.228103Z","level":"info","event":"  - Days back: 1","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:13.228157Z","level":"info","event":"  - Specific date: None (use days_back)","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:13.228216Z","level":"info","event":"  - Max execution time: 3600 seconds (60.0 minutes)","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:13.230096Z","level":"info","event":"ğŸš€ Running Airflow scraper command: /home/airflow/.local/bin/python /opt/airflow/scripts/google_scraper/scraping/run_scraper_airflow.py --dias 1 --max_time 3600 --debug","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:13.230990Z","level":"info","event":"â° Process timeout will be: 3900 seconds (65.0 minutes)","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:13.231049Z","level":"info","event":"â° Waiting for process completion with timeout: 3900 seconds","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:13.557989Z","level":"info","event":"ğŸ“‹ A iniciar scraper do Google News (versÃ£o Airflow)","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:13.558245Z","level":"info","event":"ğŸ“‹ ParÃ¢metros: dias=1, date=None, max_time=3600, quiet=False","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:13.558318Z","level":"info","event":"ğŸ“‹ ğŸ“ Ficheiro de saÃ­da: /opt/airflow/data/raw/2025/06/04/intermediate_google_news_20250604.csv","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:13.558379Z","level":"info","event":"ğŸ“‹ â±ï¸ Tempo mÃ¡ximo de execuÃ§Ã£o: 3600 segundos","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:13.558464Z","level":"info","event":"ğŸ“‹ ğŸš€ A iniciar funÃ§Ã£o do scraper otimizada para Airflow","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:13.558520Z","level":"info","event":"ğŸ“‹ âš™ï¸  ParÃ¢metros: days_back=1, search_date=None, max_time=3600s","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:13.558591Z","level":"info","event":"ğŸ“‹ ğŸš€ A iniciar o scraper do Google News...","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:13.558647Z","level":"info","event":"ğŸ“‹ ğŸ“… Data: atual, Dias anteriores: 1","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:13.679912Z","level":"info","event":"ğŸ“‹ ğŸ“ Diretoria do script: /opt/airflow/scripts/google_scraper/scraping","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:13.680086Z","level":"info","event":"ğŸ“‹ ğŸ“ Raiz do projeto: /opt/airflow","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:13.680153Z","level":"info","event":"ğŸ“‹ ğŸ”§ A carregar ficheiros de configuraÃ§Ã£o...","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:14.578489Z","level":"info","event":"ğŸ“‹ ğŸ” A procurar ficheiros de configuraÃ§Ã£o em: ['/opt/airflow/config', '/opt/airflow/scripts/google_scraper/scraping/config', 'config']","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:14.581027Z","level":"info","event":"ğŸ“‹ 2025-06-05 15:41:14,578 - run_scraper_airflow - ERROR - âŒ NÃ£o foi possÃ­vel carregar o ficheiro keywords.json","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:14.585027Z","level":"info","event":"ğŸ“‹ 2025-06-05 15:41:14,578 - run_scraper_airflow - ERROR - ğŸ” Procurado em: ['/opt/airflow/config', '/opt/airflow/scripts/google_scraper/scraping/config', 'config']","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:14.585218Z","level":"info","event":"ğŸ“‹ 2025-06-05 15:41:14,578 - run_scraper_airflow - ERROR - âŒ Erro ao carregar configuraÃ§Ã£o: keywords.json nÃ£o encontrado","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:14.585286Z","level":"info","event":"ğŸ“‹ 2025-06-05 15:41:14,579 - run_scraper_airflow - ERROR - âŒ Scraper falhou: keywords.json nÃ£o encontrado","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:14.680422Z","level":"info","event":"âŒ Airflow scraper failed with return code 1","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:14.680614Z","level":"info","event":"âŒ Unexpected error in scraper task: Airflow scraper failed with return code 1","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:14.680720Z","level":"info","event":"ğŸ”„ Fallback: using original run_scraper.py...","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:14.680850Z","level":"info","event":"ğŸš€ Running fallback scraper command: python /opt/airflow/scripts/google_scraper/scraping/run_scraper.py --dias 1","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:14.680910Z","level":"info","event":"â° Fallback timeout: 3600 seconds (60.0 minutes)","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:14.711738Z","level":"info","event":"ğŸ“‹ Fallback scraper stdout:","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:14.711886Z","level":"info","event":"âš ï¸ Fallback scraper stderr: python: can't open file '/opt/airflow/scripts/google_scraper/scraping/run_scraper.py': [Errno 2] No such file or directory","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:14.711959Z","level":"info","event":"","chan":"stdout","logger":"task"}
{"timestamp":"2025-06-05T14:41:14.711769","level":"error","event":"Task failed with exception","logger":"task","error_detail":[{"exc_type":"Exception","exc_value":"All scraper methods failed. Last error: python: can't open file '/opt/airflow/scripts/google_scraper/scraping/run_scraper.py': [Errno 2] No such file or directory\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.11/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":838,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.11/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1130,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.11/site-packages/airflow/sdk/bases/operator.py","lineno":408,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/standard/operators/python.py","lineno":212,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.11/site-packages/airflow/providers/standard/operators/python.py","lineno":235,"name":"execute_callable"},{"filename":"/home/airflow/.local/lib/python3.11/site-packages/airflow/sdk/execution_time/callback_runner.py","lineno":81,"name":"run"},{"filename":"/opt/airflow/dags/google_scraper_dag.py","lineno":174,"name":"run_scraper_task"}]},{"exc_type":"Exception","exc_value":"Airflow scraper failed with return code 1","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/opt/airflow/dags/google_scraper_dag.py","lineno":129,"name":"run_scraper_task"}]}]}
